import requests
import json
import logging
from typing import Dict, Any, Optional, List
from config import api_config

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AIServiceManager:
    """AIæœåŠ¡ç®¡ç†å™¨ - ç»Ÿä¸€ç®¡ç†å¤šä¸ªAIæ¨¡å‹çš„è°ƒç”¨"""
    
    def __init__(self):
        self.config = api_config
        self.default_model = 'deepseek-chat'  # é»˜è®¤ä½¿ç”¨DeepSeek Chatï¼ˆå¤‡ç”¨ï¼‰
    
    def get_default_model(self):
        """è·å–é»˜è®¤æ¨¡å‹ï¼Œä¼˜å…ˆä»Flask sessionè·å–ç”¨æˆ·è®¾ç½®"""
        try:
            from flask import session
            # ä»sessionè·å–ç”¨æˆ·è®¾ç½®çš„é»˜è®¤æ¨¡å‹
            user_default = session.get('default_ai_model')
            if user_default:
                return user_default
        except (ImportError, RuntimeError):
            # å¦‚æœä¸åœ¨Flaskä¸Šä¸‹æ–‡ä¸­ï¼Œä½¿ç”¨ç¡¬ç¼–ç é»˜è®¤å€¼
            pass
        return self.default_model
    
    def chat(self, message, context=None):
        """å‘é€èŠå¤©æ¶ˆæ¯ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹"""
        messages = []
        if context:
            messages.append({
                'role': 'system',
                'content': context
            })
        messages.append({
            'role': 'user',
            'content': message
        })
        
        return self.call_ai_model(self.get_default_model(), messages)
    
    def chat_with_model(self, message, model_spec, context=None):
        """ä½¿ç”¨æŒ‡å®šçš„AIæ¨¡å‹å‘é€èŠå¤©æ¶ˆæ¯
        
        Args:
            message: èŠå¤©æ¶ˆæ¯
            model_spec: æ¨¡å‹åç§°ï¼Œå¦‚ 'deepseek-reasoner', 'gemini-pro' ç­‰
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
        """
        messages = []
        if context:
            messages.append({
                'role': 'system',
                'content': context
            })
        messages.append({
            'role': 'user',
            'content': message
        })
        
        return self.call_ai_model(model_spec, messages)
    
    def get_available_models(self) -> List[Dict[str, Any]]:
        """è·å–å¯ç”¨çš„AIæ¨¡å‹åˆ—è¡¨"""
        models = []
        for name, config in self.config.get_available_models().items():
            models.append({
                'id': name,
                'name': config['description'],
                'model': config['model'],
                'available': True
            })
        return models
    
    def _map_model_name(self, frontend_model_name: str) -> str:
        """æ™ºèƒ½æ˜ å°„å‰ç«¯æ¨¡å‹åç§°åˆ°åç«¯é…ç½®çš„æ¨¡å‹åç§°"""
        # å¦‚æœå·²ç»æ˜¯åç«¯æ ¼å¼ï¼Œç›´æ¥è¿”å›
        if ':' not in frontend_model_name:
            return frontend_model_name
        
        # è§£æå‰ç«¯æ ¼å¼: provider:model
        try:
            provider, model = frontend_model_name.split(':', 1)
        except ValueError:
            logger.warning(f"æ— æ•ˆçš„æ¨¡å‹åç§°æ ¼å¼: {frontend_model_name}")
            return frontend_model_name
        
        # ç²¾ç¡®çš„æ¨¡å‹æ˜ å°„è§„åˆ™ï¼šåªæœ‰ç‰¹å®šæ¨¡å‹æ‰æ˜ å°„åˆ°åç«¯é…ç½®
        exact_model_mapping = {
            'deepseek:deepseek-reasoner': 'deepseek-reasoner',
            'deepseek:deepseek-chat': 'deepseek-chat',
            'moonshot:moonshot-v1-1t': 'moonshot-kimi-k2',
            'moonshot:moonshot-v1-8k': 'moonshot-kimi-k2',
            'moonshot:moonshot-v1-32k': 'moonshot-kimi-k2',
            'openai:gpt-4': 'openai-gpt4',
            'openai:gpt-4-turbo': 'openai-gpt4',
            'gemini:gemini-pro': 'gemini-pro',
            'xai:grok-3-mini': 'grok-4',
            'xai:grok-4': 'grok-4'
        }
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç²¾ç¡®åŒ¹é…
        mapped_name = exact_model_mapping.get(frontend_model_name.lower())
        if mapped_name:
            logger.info(f"æ™ºèƒ½æ˜ å°„æ¨¡å‹: {frontend_model_name} -> {mapped_name}")
            return mapped_name
        
        # å¦‚æœæ²¡æœ‰ç²¾ç¡®åŒ¹é…ï¼Œç›´æ¥è¿”å›åŸå§‹åç§°ï¼ˆä¸è¿›è¡Œæ˜ å°„ï¼‰
        logger.info(f"ä½¿ç”¨åŸå§‹æ¨¡å‹åç§°: {frontend_model_name}")
        return frontend_model_name

    def _adjust_model_parameters(self, model_name: str, temperature: float, max_tokens: int) -> Dict[str, Any]:
        """æ ¹æ®ä¸åŒæ¨¡å‹çš„ç‰¹ç‚¹è°ƒæ•´å‚æ•°ï¼Œè®©æ¯ä¸ªæ¨¡å‹å±•ç°å…¶ç‹¬ç‰¹æ€§"""
        # ä¸åŒæ¨¡å‹çš„ç‰¹è‰²å‚æ•°é…ç½®
        model_configs = {
            'deepseek-chat': {
                'temperature': 0.7,  # å¯¹è¯æ¨¡å‹ï¼Œå¹³è¡¡åˆ›é€ æ€§
                'max_tokens': 8192,  # DeepSeek Chatæœ€å¤§æ”¯æŒ8192
                'description': 'å¯¹è¯ä¸“å®¶ï¼Œå›ç­”å‡†ç¡®ï¼Œå†…å®¹è¯¦å®'
            },
            'deepseek-reasoner': {
                'temperature': 0.3,  # æ¨ç†æ¨¡å‹ï¼Œé™ä½éšæœºæ€§
                'max_tokens': 12000,  # æ¨ç†æ¨¡å‹é€šå¸¸è¾“å‡ºæ›´è¯¦ç»†
                'description': 'æ·±åº¦æ¨ç†ï¼Œé€»è¾‘ä¸¥å¯†ï¼Œè¶…é•¿å†…å®¹'
            },
            'moonshot-kimi-k2': {
                'temperature': 0.8,  # åˆ›æ„æ¨¡å‹ï¼Œå¢åŠ åˆ›é€ æ€§
                'max_tokens': 16000,  # é•¿æ–‡æœ¬å¤„ç†ä¸“å®¶ï¼Œæœ€å¤§è¾“å‡º
                'description': 'åˆ›æ„ä¸°å¯Œï¼Œè¡¨è¾¾ç”ŸåŠ¨ï¼Œè¶…é•¿æ–‡æœ¬'
            },
            'openai-gpt4': {
                'temperature': 0.7,  # å¹³è¡¡çš„é€šç”¨æ¨¡å‹
                'max_tokens': 10000,  # å¤§å¹…å¢åŠ è¾“å‡ºé•¿åº¦
                'description': 'é€šç”¨å‡è¡¡ï¼Œè¡¨è¾¾è‡ªç„¶ï¼Œè¯¦ç»†å†…å®¹'
            },
            'gemini-pro': {
                'temperature': 0.9,  # Googleæ¨¡å‹ï¼Œå¢åŠ å¤šæ ·æ€§
                'max_tokens': 12000,  # å¤šæ¨¡æ€æ¨¡å‹ï¼Œé•¿å†…å®¹
                'description': 'å¤šå…ƒæ€ç»´ï¼Œè§†è§’ç‹¬ç‰¹ï¼Œä¸°å¯Œå†…å®¹'
            },
            'grok-4': {
                'temperature': 1.0,  # Grokæ¨¡å‹ï¼Œæœ€å¤§åˆ›é€ æ€§
                'max_tokens': 14000,  # å¼ºå¤§çš„æ¨ç†èƒ½åŠ›ï¼Œè¶…é•¿è¾“å‡º
                'description': 'å¹½é»˜é£è¶£ï¼Œæ€ç»´è·³è·ƒï¼Œè¶…è¯¦ç»†'
            }
        }
        
        config = model_configs.get(model_name, {
            'temperature': temperature,
            'max_tokens': max_tokens,
            'description': 'æ ‡å‡†é…ç½®'
        })
        
        logger.info(f"æ¨¡å‹ {model_name} ä½¿ç”¨ç‰¹è‰²é…ç½®: {config['description']}, temperature={config['temperature']}, max_tokens={config['max_tokens']}")
        
        return {
            'temperature': config['temperature'],
            'max_tokens': config['max_tokens']
        }

    def _get_model_style_guidance(self, model_name: str) -> str:
        """æ ¹æ®ä¸åŒæ¨¡å‹çš„ç‰¹ç‚¹æä¾›é£æ ¼æŒ‡å¯¼"""
        if not model_name:
            return ""
            
        style_guides = {
             'deepseek-reasoner': """
ç‰¹åˆ«è¦æ±‚ï¼ˆåŸºäºDeepSeekæ¨ç†æ¨¡å‹ç‰¹ç‚¹ï¼‰ï¼š
- è¯·è¿›è¡Œæ·±åº¦é€»è¾‘åˆ†æï¼Œæä¾›è¯¦ç»†çš„æ¨ç†è¿‡ç¨‹å’Œæ•°æ®æ”¯æ’‘
- æ¯ä¸ªé”€å”®æ­¥éª¤éƒ½è¦æœ‰æ¸…æ™°çš„é€»è¾‘æ”¯æ’‘ã€åŸå› è¯´æ˜å’Œå®æ–½ç»†èŠ‚
- å†…å®¹è¦ä¸¥è°¨ã€ä¸“ä¸šï¼ŒåŒ…å«å…·ä½“çš„æ¡ˆä¾‹åˆ†æå’Œæ•°æ®è®ºè¯
- å­—æ•°è¦æ±‚ï¼šæ¯éƒ¨åˆ†è‡³å°‘500å­—ï¼Œæ€»å­—æ•°ä¸å°‘äº2500å­—ï¼Œå†…å®¹è¶Šè¯¦ç»†è¶Šå¥½
- é‡ç‚¹çªå‡ºæ•°æ®åˆ†æã€ç†æ€§è¯´æœå’Œæ·±åº¦æ€è€ƒ
- è¯·æä¾›å…·ä½“çš„è¯æœ¯ç¤ºä¾‹ã€åº”å¯¹ç­–ç•¥å’Œå®æ–½æ­¥éª¤""",
             
             'moonshot-kimi-k2': """
ç‰¹åˆ«è¦æ±‚ï¼ˆåŸºäºMoonshoté•¿æ–‡æœ¬å¤„ç†ç‰¹ç‚¹ï¼‰ï¼š
- è¯·ç”Ÿæˆæå…¶ä¸°å¯Œè¯¦ç»†çš„å†…å®¹ï¼Œå……åˆ†å±•ç°åˆ›æ„å’Œè¡¨è¾¾èƒ½åŠ›
- è¯­è¨€è¦ç”ŸåŠ¨æ´»æ³¼ï¼Œå¯Œæœ‰æ„ŸæŸ“åŠ›å’Œè¯´æœåŠ›ï¼Œä½¿ç”¨ä¸°å¯Œçš„ä¿®è¾æ‰‹æ³•
- å¤§é‡ä½¿ç”¨æ¯”å–»ã€æ•…äº‹ã€æ¡ˆä¾‹ç­‰ç”ŸåŠ¨çš„è¡¨è¾¾æ–¹å¼
- å­—æ•°è¦æ±‚ï¼šæ¯éƒ¨åˆ†è‡³å°‘600å­—ï¼Œæ€»å­—æ•°ä¸å°‘äº3000å­—ï¼Œè¶Šé•¿è¶Šå¥½
- é‡ç‚¹çªå‡ºæƒ…æ„Ÿå…±é¸£ã€åˆ›æ„è¡¨è¾¾å’Œç”ŸåŠ¨æè¿°
- è¯·æä¾›è¯¦ç»†çš„åœºæ™¯æè¿°ã€å¯¹è¯ç¤ºä¾‹å’Œæƒ…æ„Ÿå¼•å¯¼æŠ€å·§""",
             
             'openai-gpt4': """
ç‰¹åˆ«è¦æ±‚ï¼ˆåŸºäºGPT-4é€šç”¨å‡è¡¡ç‰¹ç‚¹ï¼‰ï¼š
- è¯·ä¿æŒä¸“ä¸šè€Œè‡ªç„¶çš„è¡¨è¾¾é£æ ¼ï¼Œå†…å®¹è¦å…¨é¢è¯¦ç»†
- å†…å®¹è¦å¹³è¡¡ç†æ€§åˆ†æå’Œæƒ…æ„Ÿè¯‰æ±‚ï¼Œæä¾›å®Œæ•´çš„è§£å†³æ–¹æ¡ˆ
- è¯­è¨€è¦æµç•…æ˜“æ‡‚ï¼Œé€»è¾‘æ¸…æ™°ï¼Œç»“æ„å®Œæ•´
- å­—æ•°è¦æ±‚ï¼šæ¯éƒ¨åˆ†è‡³å°‘400å­—ï¼Œæ€»å­—æ•°ä¸å°‘äº2000å­—ï¼Œå†…å®¹è¦å……å®
- é‡ç‚¹çªå‡ºä¸“ä¸šæ€§ã€å¯æ“ä½œæ€§å’Œå®ç”¨æ€§
- è¯·æä¾›å…·ä½“çš„æ“ä½œæŒ‡å—ã€è¯æœ¯æ¨¡æ¿å’Œå®æ–½å»ºè®®""",
             
             'gemini-pro': """
ç‰¹åˆ«è¦æ±‚ï¼ˆåŸºäºGeminiå¤šå…ƒæ€ç»´ç‰¹ç‚¹ï¼‰ï¼š
- è¯·ä»å¤šä¸ªè§’åº¦æ·±å…¥åˆ†æå®¢æˆ·éœ€æ±‚å’Œé”€å”®ç­–ç•¥
- å†…å®¹è¦æœ‰ç‹¬ç‰¹çš„è§†è§’å’Œåˆ›æ–°æ€ç»´ï¼Œæä¾›å¤šç»´åº¦çš„è§£å†³æ–¹æ¡ˆ
- ç»“åˆè¡Œä¸šè¶‹åŠ¿ã€å¸‚åœºæ´å¯Ÿå’Œå‰æ²¿ç†å¿µ
- å­—æ•°è¦æ±‚ï¼šæ¯éƒ¨åˆ†è‡³å°‘550å­—ï¼Œæ€»å­—æ•°ä¸å°‘äº2800å­—ï¼Œè§†è§’è¦ä¸°å¯Œ
- é‡ç‚¹çªå‡ºå¤šç»´åº¦åˆ†æã€å‰ç»æ€§æ€è€ƒå’Œåˆ›æ–°ç­–ç•¥
- è¯·æä¾›å¤šç§æ–¹æ¡ˆé€‰æ‹©ã€è¶‹åŠ¿åˆ†æå’Œåˆ›æ–°æ–¹æ³•""",
             
             'grok-4': """
ç‰¹åˆ«è¦æ±‚ï¼ˆåŸºäºGrokå¹½é»˜é£è¶£ç‰¹ç‚¹ï¼‰ï¼š
- è¯·åœ¨ä¿æŒä¸“ä¸šçš„åŒæ—¶ï¼Œå¤§é‡åŠ å…¥å¹½é»˜å…ƒç´ å’Œåˆ›æ„è¡¨è¾¾
- è¯­è¨€è¦æå…·äº²å’ŒåŠ›ï¼Œå®¹æ˜“æ‹‰è¿‘ä¸å®¢æˆ·çš„è·ç¦»ï¼Œé£æ ¼ç‹¬ç‰¹
- ä½¿ç”¨è½»æ¾å¹½é»˜çš„è¡¨è¾¾æ–¹å¼ï¼Œä½†ä¿æŒä¸“ä¸šæ€§å’Œå®ç”¨æ€§
- å­—æ•°è¦æ±‚ï¼šæ¯éƒ¨åˆ†è‡³å°‘650å­—ï¼Œæ€»å­—æ•°ä¸å°‘äº3200å­—ï¼Œé£æ ¼è¦çªå‡º
- é‡ç‚¹çªå‡ºäººæ€§åŒ–æ²Ÿé€šã€åˆ›æ–°è¡¨è¾¾å’Œç‹¬ç‰¹é£æ ¼
- è¯·æä¾›å¹½é»˜çš„å¯¹è¯æŠ€å·§ã€åˆ›æ„çš„æ²Ÿé€šæ–¹å¼å’Œä¸ªæ€§åŒ–çš„è¡¨è¾¾"""
         }
        
        return style_guides.get(model_name, "")

    def call_ai_model(self, model_name: str, messages: List[Dict[str, str]], 
                      temperature: float = 0.7, max_tokens: int = 16000) -> Dict[str, Any]:
        """è°ƒç”¨æŒ‡å®šçš„AIæ¨¡å‹"""
        try:
            # æ˜ å°„æ¨¡å‹åç§°
            mapped_model_name = self._map_model_name(model_name)
            
            model_config = self.config.get_ai_model_config(mapped_model_name)
            if not model_config or not model_config.get('api_key'):
                raise ValueError(f"æ¨¡å‹ {mapped_model_name} ä¸å¯ç”¨æˆ–ç¼ºå°‘APIå¯†é’¥")
            
            # æ ¹æ®ä¸åŒæ¨¡å‹è°ƒæ•´å‚æ•°ä»¥å±•ç°å„è‡ªç‰¹è‰²
            adjusted_params = self._adjust_model_parameters(mapped_model_name, temperature, max_tokens)
            
            # æ ¹æ®ä¸åŒçš„æ¨¡å‹è°ƒç”¨ä¸åŒçš„API
            if mapped_model_name == 'gemini-pro':
                return self._call_gemini(model_config, messages, adjusted_params['temperature'], adjusted_params['max_tokens'])
            else:
                return self._call_openai_compatible(model_config, messages, adjusted_params['temperature'], adjusted_params['max_tokens'])
        
        except Exception as e:
            logger.error(f"è°ƒç”¨AIæ¨¡å‹ {model_name} å¤±è´¥: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'message': 'æŠ±æ­‰ï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚'
            }
    
    def _call_openai_compatible(self, config: Dict[str, Any], messages: List[Dict[str, str]], 
                               temperature: float, max_tokens: int) -> Dict[str, Any]:
        """è°ƒç”¨OpenAIå…¼å®¹çš„API"""
        headers = {
            'Authorization': f'Bearer {config["api_key"]}',
            'Content-Type': 'application/json'
        }
        
        payload = {
            'model': config['model'],
            'messages': messages,
            'temperature': temperature,
            'max_tokens': max_tokens
        }
        
        response = requests.post(
            f"{config['base_url']}/chat/completions",
            headers=headers,
            json=payload,
            timeout=120  # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°120ç§’
        )
        
        if response.status_code == 200:
            result = response.json()
            return {
                'success': True,
                'message': result['choices'][0]['message']['content'],
                'usage': result.get('usage', {}),
                'model': config['model']
            }
        else:
            raise Exception(f"APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")
    
    def _call_gemini(self, config: Dict[str, Any], messages: List[Dict[str, str]], 
                    temperature: float, max_tokens: int) -> Dict[str, Any]:
        """è°ƒç”¨Google Gemini API"""
        # è½¬æ¢æ¶ˆæ¯æ ¼å¼ä¸ºGeminiæ ¼å¼
        contents = []
        for msg in messages:
            if msg['role'] == 'user':
                contents.append({
                    'parts': [{'text': msg['content']}]
                })
        
        payload = {
            'contents': contents,
            'generationConfig': {
                'temperature': temperature,
                'maxOutputTokens': max_tokens
            }
        }
        
        response = requests.post(
            f"{config['base_url']}/models/{config['model']}:generateContent?key={config['api_key']}",
            json=payload,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            if 'candidates' in result and result['candidates']:
                content = result['candidates'][0]['content']['parts'][0]['text']
                return {
                    'success': True,
                    'message': content,
                    'model': config['model']
                }
            else:
                raise Exception("Gemini APIè¿”å›ç©ºç»“æœ")
        else:
            raise Exception(f"Gemini APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")
    
    def generate_customer_analysis(self, customer_data: Dict[str, Any], 
                                 interactions: List[Dict[str, Any]] = None,
                                 model_name: str = None) -> Dict[str, Any]:
        """ç”Ÿæˆå®¢æˆ·åˆ†æ"""
        if not model_name:
            model_name = self.get_default_model()
        
        # æ„å»ºåˆ†ææç¤º
        prompt = self._build_analysis_prompt(customer_data, interactions)
        
        messages = [
            {
                'role': 'system',
                'content': '''ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„CRMé”€å”®åˆ†æå¸ˆï¼Œæ“…é•¿å®¢æˆ·ç”»åƒåˆ†æå’Œé”€å”®ç­–ç•¥åˆ¶å®šã€‚
                è¯·åŸºäºæä¾›çš„å®¢æˆ·ä¿¡æ¯å’Œäº’åŠ¨å†å²ï¼Œç”Ÿæˆè¯¦ç»†çš„å®¢æˆ·åˆ†ææŠ¥å‘Šã€‚
                
                åˆ†æåº”åŒ…æ‹¬ï¼š
                1. å®¢æˆ·ç”»åƒæ€»ç»“
                2. æ²Ÿé€šé£æ ¼åå¥½
                3. æ½œåœ¨éœ€æ±‚å’Œç—›ç‚¹
                4. æˆäº¤æ¦‚ç‡è¯„ä¼°
                5. ä¸‹ä¸€æ­¥è¡ŒåŠ¨å»ºè®®
                
                è¯·ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€å›ç­”ï¼Œé‡ç‚¹çªå‡ºå¯æ‰§è¡Œçš„é”€å”®å»ºè®®ã€‚'''
            },
            {
                'role': 'user',
                'content': prompt
            }
        ]
        
        return self.call_ai_model(model_name, messages, temperature=0.3)
    
    def generate_sales_script(self, customer_data: Dict[str, Any], 
                            script_type: str = 'opening',
                            methodology: str = 'straightLine',
                            model_name: str = None,
                            advanced_settings: Dict[str, Any] = None) -> Dict[str, Any]:
        """ç”Ÿæˆé”€å”®è¯æœ¯"""
        if not model_name:
            model_name = self.get_default_model()
        
        # æ„å»ºè¯æœ¯ç”Ÿæˆæç¤º
        prompt = self._build_script_prompt(customer_data, script_type, methodology, advanced_settings, model_name)
        
        messages = [
            {
                'role': 'system',
                'content': f'''ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é”€å”®è¯æœ¯ä¸“å®¶ï¼Œç²¾é€šå¤šç§é”€å”®æ–¹æ³•è®ºã€‚
                å½“å‰ä½¿ç”¨çš„é”€å”®æ–¹æ³•è®ºæ˜¯ï¼š{methodology}
                
                è¯·ä¸ºå®¢æˆ·ç”Ÿæˆä¸“ä¸šã€ä¸ªæ€§åŒ–çš„é”€å”®è¯æœ¯ã€‚è¯æœ¯åº”è¯¥ï¼š
                1. ç¬¦åˆæ‰€é€‰é”€å”®æ–¹æ³•è®ºçš„åŸåˆ™
                2. é’ˆå¯¹å®¢æˆ·çš„å…·ä½“æƒ…å†µå®šåˆ¶
                3. è‡ªç„¶æµç•…ï¼Œä¸æ˜¾ç”Ÿç¡¬
                4. åŒ…å«å…·ä½“çš„è¡ŒåŠ¨æŒ‡å¯¼
                
                è¯·æä¾›3-5ä¸ªä¸åŒçš„è¯æœ¯é€‰é¡¹ï¼Œæ¯ä¸ªéƒ½è¦æ ‡æ³¨ä½¿ç”¨åœºæ™¯ã€‚'''
            },
            {
                'role': 'user',
                'content': prompt
            }
        ]
        
        return self.call_ai_model(model_name, messages, temperature=0.7)
    
    def analyze_conversation(self, conversation_content: str, 
                           customer_data: Dict[str, Any] = None,
                           model_name: str = None) -> Dict[str, Any]:
        """åˆ†æå¯¹è¯å†…å®¹"""
        if not model_name:
            model_name = self.get_default_model()
        
        prompt = f"""è¯·åˆ†æä»¥ä¸‹å¯¹è¯å†…å®¹ï¼š
        
        å¯¹è¯å†…å®¹ï¼š
        {conversation_content}
        
        {f'å®¢æˆ·èƒŒæ™¯ï¼š{json.dumps(customer_data, ensure_ascii=False, indent=2)}' if customer_data else ''}
        
        è¯·æä¾›ï¼š
        1. å¯¹è¯æƒ…ç»ªåˆ†æï¼ˆç§¯æ/ä¸­æ€§/æ¶ˆæï¼‰
        2. å…³é”®ä¿¡æ¯æå–
        3. å®¢æˆ·å…´è¶£ç‚¹å’Œç—›ç‚¹
        4. é”€å”®æœºä¼šè¯„ä¼°
        5. ä¸‹æ¬¡è·Ÿè¿›å»ºè®®
        """
        
        messages = [
            {
                'role': 'system',
                'content': 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¯¹è¯åˆ†æå¸ˆï¼Œæ“…é•¿ä»é”€å”®å¯¹è¯ä¸­æå–å…³é”®ä¿¡æ¯å’Œæ´å¯Ÿã€‚'
            },
            {
                'role': 'user',
                'content': prompt
            }
        ]
        
        return self.call_ai_model(model_name, messages, temperature=0.3)
    
    def _build_analysis_prompt(self, customer_data: Dict[str, Any], 
                              interactions: List[Dict[str, Any]] = None) -> str:
        """æ„å»ºå®¢æˆ·åˆ†ææç¤º"""
        prompt = f"""è¯·åˆ†æä»¥ä¸‹å®¢æˆ·ä¿¡æ¯ï¼š
        
        å®¢æˆ·åŸºæœ¬ä¿¡æ¯ï¼š
        - å§“åï¼š{customer_data.get('name', 'æœªçŸ¥')}
        - å…¬å¸ï¼š{customer_data.get('company', 'æœªçŸ¥')}
        - èŒä½ï¼š{customer_data.get('position', 'æœªçŸ¥')}
        - è¡Œä¸šï¼š{customer_data.get('industry', 'æœªçŸ¥')}
        - ä¼˜å…ˆçº§ï¼š{customer_data.get('priority', 'ä¸­ç­‰')}
        """
        
        if interactions:
            prompt += "\n\næœ€è¿‘äº’åŠ¨è®°å½•ï¼š\n"
            for interaction in interactions[-5:]:  # åªå–æœ€è¿‘5æ¡è®°å½•
                prompt += f"- {interaction.get('created_at', '')}ï¼š{interaction.get('content', '')}\n"
        
        return prompt
    
    def _build_script_prompt(self, customer_data: Dict[str, Any], 
                           script_type: str, methodology: str,
                           advanced_settings: Dict[str, Any] = None,
                           model_name: str = None) -> str:
        """æ„å»ºè¯æœ¯ç”Ÿæˆæç¤º"""
        script_types = {
            'opening': 'å¼€åœºç™½',
            'discovery': 'éœ€æ±‚æŒ–æ˜',
            'needs_discovery': 'éœ€æ±‚æŒ–æ˜', 
            'presentation': 'æ–¹æ¡ˆå±•ç¤º',
            'objection': 'å¼‚è®®å¤„ç†',
            'objection_handling': 'å¼‚è®®å¤„ç†',
            'closing': 'æˆäº¤ä¿ƒæˆ',
            'follow_up': 'è·Ÿè¿›è¯æœ¯',
            'initial_contact': 'åˆæ¬¡æ¥è§¦',
            'pain_point_discovery': 'ç—›ç‚¹æŒ–æ˜'
        }
        
        methodologies = {
            'straightLine': 'åå°”è¡—ä¹‹ç‹¼ç›´çº¿é”€å”®æ³•',
            'straight_line': 'ç›´çº¿é”€å”®æ³•',
            'spin': 'SPINé”€å”®æ³•',
            'challenger': 'æŒ‘æˆ˜è€…é”€å”®æ³•',
            'consultative': 'é¡¾é—®å¼é”€å”®æ³•',
            'solution': 'è§£å†³æ–¹æ¡ˆé”€å”®æ³•',
            'value': 'ä»·å€¼é”€å”®æ³•',
            'sandler': 'æ¡‘å¾·æ‹‰ä¸ƒæ­¥é”€å”®æ³•',
            'obppc': 'OBPPCé”€å”®æ¨¡å‹'
        }
        
        # æ ¹æ®ä¸åŒçš„é”€å”®æƒ…å†µå®šåˆ¶promptå†…å®¹
        situation_guidance = self._get_situation_guidance(script_type, methodology)
        
        # æ ¹æ®é”€å”®æƒ…å†µå®šåˆ¶ä¸åŒçš„å†…å®¹é‡ç‚¹
        content_focus = self._get_content_focus(script_type)
        
        # è·å–é”€å”®æ–¹æ³•è®ºçš„è¯¦ç»†æŒ‡å¯¼
        methodology_guidance = self._get_methodology_detailed_guidance(methodology)
        
        # å¤„ç†é«˜çº§è®¾ç½®
        advanced_guidance = self._build_advanced_settings_guidance(advanced_settings) if advanced_settings else ""
        
        # æ·»åŠ æ¨¡å‹ç‰¹è‰²æŒ‡å¯¼
        model_guidance = self._get_model_style_guidance(model_name) if model_name else ""
        
        prompt = f"""ğŸš¨ é‡è¦æç¤ºï¼šè¯·ç”Ÿæˆè¶…é•¿ã€è¶…è¯¦ç»†çš„é”€å”®è¯æœ¯å†…å®¹ï¼ğŸš¨
        
        {model_guidance}
        
        è¯·ä¸ºä»¥ä¸‹å®¢æˆ·ç”Ÿæˆå®Œæ•´çš„é”€å”®è¯æœ¯ï¼Œå¿…é¡»åŒ…å«5ä¸ªéƒ¨åˆ†ã€‚
        
        å®¢æˆ·ä¿¡æ¯ï¼š
        - å§“åï¼š{customer_data.get('name', 'æœªçŸ¥')}
        - å…¬å¸ï¼š{customer_data.get('company', 'æœªçŸ¥')}
        - èŒä½ï¼š{customer_data.get('position', 'æœªçŸ¥')}
        - è¡Œä¸šï¼š{customer_data.get('industry', 'æœªçŸ¥')}
        {f'- é¡¹ç›®èƒŒæ™¯ï¼š{customer_data.get("project_background", "")}' if customer_data.get('project_background') else ''}
        
        é”€å”®æ–¹æ³•è®ºï¼š{methodologies.get(methodology, methodology)}
        å½“å‰é”€å”®æƒ…å†µï¼š{script_types.get(script_type, script_type)}
        
        {situation_guidance}
        
        {methodology_guidance}
        
        {content_focus}
        
        {advanced_guidance}
        
        âš ï¸ å†æ¬¡å¼ºè°ƒï¼šæ¯ä¸ªéƒ¨åˆ†éƒ½å¿…é¡»éå¸¸è¯¦ç»†ï¼ŒåŒ…å«å…·ä½“çš„è¯æœ¯ç¤ºä¾‹ã€å®æ–½æ­¥éª¤å’Œè¯¦ç»†è¯´æ˜ï¼âš ï¸
        
        è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼Œç¡®ä¿æ¯ä¸ªå­—æ®µéƒ½æœ‰å…·ä½“ã€è¯¦ç»†çš„å†…å®¹ï¼š
        
        """
        
        # æ ¹æ®é”€å”®æƒ…å†µåŠ¨æ€è°ƒæ•´JSONå­—æ®µ
        json_fields = self._get_dynamic_json_fields(script_type, customer_data)
        prompt += json_fields
        
        prompt += """
        
        é‡è¦è¦æ±‚ï¼š
        1. å¿…é¡»è¿”å›æ ‡å‡†JSONæ ¼å¼ï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–æ–‡å­—
        2. æ¯ä¸ªå­—æ®µçš„å†…å®¹è¦å…·ä½“ã€å®ç”¨ï¼Œä¸èƒ½æ˜¯ç©ºæ³›çš„æ¨¡æ¿
        3. è¯æœ¯è¦ç¬¦åˆ{methodologies.get(methodology, methodology)}çš„æ ¸å¿ƒåŸåˆ™
        4. å†…å®¹è¦é’ˆå¯¹{customer_data.get('industry', 'è¡Œä¸š')}è¡Œä¸šç‰¹ç‚¹å®šåˆ¶
        5. è¯­è¨€è¦ä¸“ä¸šã€è‡ªç„¶ã€æœ‰è¯´æœåŠ›
        6. ç‰¹åˆ«æ³¨æ„å½“å‰é”€å”®æƒ…å†µæ˜¯"{script_types.get(script_type, script_type)}"
        7. ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°å†…å®¹é‡ç‚¹è¦æ±‚è°ƒæ•´å„éƒ¨åˆ†çš„è¡¨è¾¾æ–¹å¼å’Œä¾§é‡ç‚¹
        
        è¯·ç›´æ¥è¿”å›JSONæ ¼å¼çš„è¯æœ¯å†…å®¹ï¼š
        """
        
        return prompt
    
    def _get_dynamic_json_fields(self, script_type: str, customer_data: Dict[str, Any]) -> str:
        """æ ¹æ®é”€å”®æƒ…å†µåŠ¨æ€ç”ŸæˆJSONå­—æ®µå®šä¹‰"""
        customer_name = customer_data.get('name', 'å®¢æˆ·')
        customer_industry = customer_data.get('industry', 'è¡Œä¸š')
        customer_position = customer_data.get('position', 'èŒä½')
        
        if script_type in ['objection_handling', 'objection']:
            return f"""{{
            "objection_acknowledgment": "å¼‚è®®ç¡®è®¤å’Œç†è§£è¯æœ¯ï¼ˆè‡³å°‘300å­—ï¼‰ï¼šé¦–å…ˆè®¤çœŸå€¾å¬å¹¶ç¡®è®¤{customer_name}çš„å…·ä½“å¼‚è®®ï¼Œè¡¨è¾¾ç†è§£å’Œå…±æƒ…ï¼Œé¿å…ç›´æ¥åé©³ï¼Œå±•ç°ä¸“ä¸šçš„æ²Ÿé€šæŠ€å·§å’Œå®¢æˆ·æœåŠ¡æ„è¯†",
            "objection_analysis": "å¼‚è®®æ·±åº¦åˆ†æè¯æœ¯ï¼ˆè‡³å°‘400å­—ï¼‰ï¼šæ·±å…¥åˆ†æå¼‚è®®èƒŒåçš„çœŸå®åŸå› å’Œæ‹…å¿§ï¼Œå¯èƒ½æ¶‰åŠé¢„ç®—ã€æ—¶é—´ã€å†³ç­–æƒã€ä¿¡ä»»åº¦ç­‰æ–¹é¢ï¼Œç»“åˆ{customer_industry}è¡Œä¸šç‰¹ç‚¹å’Œ{customer_position}è§’è‰²çš„å¸¸è§é¡¾è™‘",
            "evidence_presentation": "è¯æ®å’Œæ¡ˆä¾‹å±•ç¤ºè¯æœ¯ï¼ˆè‡³å°‘500å­—ï¼‰ï¼šæä¾›å…·ä½“çš„æ•°æ®ã€æ¡ˆä¾‹ã€è¯æ˜ææ–™æ¥åŒ–è§£å¼‚è®®ï¼ŒåŒ…å«åŒè¡Œä¸šæˆåŠŸæ¡ˆä¾‹ã€ROIåˆ†æã€é£é™©è¯„ä¼°ã€å®æ–½ä¿éšœç­‰è¯¦ç»†å†…å®¹",
            "alternative_solution": "æ›¿ä»£æ–¹æ¡ˆå’Œçµæ´»å¤„ç†è¯æœ¯ï¼ˆè‡³å°‘350å­—ï¼‰ï¼šé’ˆå¯¹å®¢æˆ·çš„å…·ä½“å¼‚è®®ï¼Œæä¾›çµæ´»çš„è§£å†³æ–¹æ¡ˆã€åˆ†é˜¶æ®µå®æ–½è®¡åˆ’ã€è¯•ç”¨æœºä¼šã€å®šåˆ¶åŒ–è°ƒæ•´ç­‰å¤šç§é€‰æ‹©",
            "objection_close": "å¼‚è®®å¤„ç†åçš„æ¨è¿›è¯æœ¯ï¼ˆè‡³å°‘250å­—ï¼‰ï¼šåœ¨åŒ–è§£å¼‚è®®åï¼Œé‡æ–°å¼•å¯¼å®¢æˆ·å…³æ³¨ä»·å€¼å’Œæ”¶ç›Šï¼Œæ¨åŠ¨å†³ç­–è¿›ç¨‹ï¼Œæ˜ç¡®ä¸‹ä¸€æ­¥å…·ä½“è¡ŒåŠ¨"
        }}"""
        elif script_type in ['closing']:
            return f"""{{
            "urgency_creation": "ç´§è¿«æ„Ÿè¥é€ è¯æœ¯ï¼ˆè‡³å°‘300å­—ï¼‰ï¼šé€šè¿‡å¸‚åœºè¶‹åŠ¿ã€ç«äº‰å‹åŠ›ã€æœºä¼šçª—å£ç­‰å› ç´ ï¼Œä¸º{customer_name}è¥é€ é‡‡å–è¡ŒåŠ¨çš„ç´§è¿«æ„Ÿï¼Œç»“åˆ{customer_industry}è¡Œä¸šçš„æ—¶æ•ˆæ€§ç‰¹ç‚¹",
            "value_reinforcement": "ä»·å€¼å¼ºåŒ–å’Œæ€»ç»“è¯æœ¯ï¼ˆè‡³å°‘400å­—ï¼‰ï¼šç³»ç»Ÿæ€§åœ°æ€»ç»“å’Œå¼ºåŒ–å‰æœŸæ²Ÿé€šä¸­ç¡®è®¤çš„ä»·å€¼ç‚¹ï¼Œé‡åŒ–æ”¶ç›Šå’ŒROIï¼Œå¼ºè°ƒè§£å†³æ–¹æ¡ˆå¯¹{customer_position}å·¥ä½œçš„ç§¯æå½±å“",
            "risk_mitigation": "é£é™©æ¶ˆé™¤å’Œä¿éšœè¯æœ¯ï¼ˆè‡³å°‘500å­—ï¼‰ï¼šè¯¦ç»†è¯´æ˜å®æ–½ä¿éšœã€å”®åæœåŠ¡ã€é£é™©æ§åˆ¶æªæ–½ï¼Œæ¶ˆé™¤å®¢æˆ·çš„æœ€åé¡¾è™‘ï¼Œæä¾›å…¨é¢çš„å®‰å…¨æ„Ÿå’Œä¿¡å¿ƒ",
            "decision_facilitation": "å†³ç­–ä¿ƒè¿›å’Œé€‰æ‹©å¼•å¯¼è¯æœ¯ï¼ˆè‡³å°‘350å­—ï¼‰ï¼šå¸®åŠ©å®¢æˆ·ç†æ¸…å†³ç­–è¦ç´ ï¼Œæä¾›å†³ç­–æ¡†æ¶å’Œè¯„ä¼°æ ‡å‡†ï¼Œå¼•å¯¼å®¢æˆ·åšå‡ºç§¯æçš„è´­ä¹°å†³å®š",
            "closing_action": "æˆäº¤ä¿ƒæˆå’Œåˆä½œå¯åŠ¨è¯æœ¯ï¼ˆè‡³å°‘250å­—ï¼‰ï¼šæ˜ç¡®æå‡ºåˆä½œå»ºè®®ï¼Œè¯¦ç»†è¯´æ˜ç­¾çº¦æµç¨‹ã€å®æ–½æ—¶é—´è¡¨ã€é¡¹ç›®å¯åŠ¨å®‰æ’ç­‰å…·ä½“è¡ŒåŠ¨è®¡åˆ’"
        }}"""
        elif script_type in ['needs_discovery', 'discovery']:
            return f"""{{
            "situation_inquiry": "ç°çŠ¶äº†è§£å’ŒèƒŒæ™¯è°ƒç ”è¯æœ¯ï¼ˆè‡³å°‘300å­—ï¼‰ï¼šæ·±å…¥äº†è§£{customer_name}å½“å‰çš„ä¸šåŠ¡ç°çŠ¶ã€ç»„ç»‡æ¶æ„ã€è¿è¥æ¨¡å¼ï¼Œç‰¹åˆ«å…³æ³¨{customer_industry}è¡Œä¸šçš„ç‰¹æ®Šæ€§å’Œ{customer_position}çš„å…·ä½“èŒè´£",
            "problem_exploration": "é—®é¢˜æŒ–æ˜å’Œç—›ç‚¹æ¢ç´¢è¯æœ¯ï¼ˆè‡³å°‘400å­—ï¼‰ï¼šé€šè¿‡å¼€æ”¾æ€§å’Œå¼•å¯¼æ€§é—®é¢˜ï¼Œæ·±åº¦æŒ–æ˜å®¢æˆ·é¢ä¸´çš„ä¸šåŠ¡æŒ‘æˆ˜ã€è¿è¥ç—›ç‚¹ã€å‘å±•ç“¶é¢ˆç­‰å…³é”®é—®é¢˜",
            "impact_analysis": "å½±å“åˆ†æå’Œåæœè¯„ä¼°è¯æœ¯ï¼ˆè‡³å°‘500å­—ï¼‰ï¼šå¸®åŠ©å®¢æˆ·åˆ†æç°æœ‰é—®é¢˜å¯¹ä¸šåŠ¡çš„å…·ä½“å½±å“ï¼ŒåŒ…æ‹¬æˆæœ¬æŸå¤±ã€æ•ˆç‡é™ä½ã€ç«äº‰åŠ£åŠ¿ç­‰å¤šç»´åº¦åæœè¯„ä¼°",
            "need_confirmation": "éœ€æ±‚ç¡®è®¤å’Œä¼˜å…ˆçº§æ’åºè¯æœ¯ï¼ˆè‡³å°‘350å­—ï¼‰ï¼šç¡®è®¤å®¢æˆ·çš„çœŸå®éœ€æ±‚å’ŒæœŸæœ›ï¼Œå¸®åŠ©å®¢æˆ·ç†æ¸…éœ€æ±‚çš„ä¼˜å…ˆçº§å’Œç´§è¿«æ€§ï¼Œå»ºç«‹æ”¹è¿›çš„å¿…è¦æ€§è®¤çŸ¥",
            "solution_direction": "è§£å†³æ–¹å‘å’Œå¯èƒ½æ€§æ¢è®¨è¯æœ¯ï¼ˆè‡³å°‘250å­—ï¼‰ï¼šåˆæ­¥æ¢è®¨è§£å†³é—®é¢˜çš„æ–¹å‘å’Œå¯èƒ½æ€§ï¼Œä¸ºåç»­çš„æ–¹æ¡ˆä»‹ç»åšå¥½é“ºå«å’ŒæœŸå¾…ç®¡ç†"
        }}"""
        elif script_type in ['follow_up']:
            return f"""{{
            "relationship_maintenance": "å…³ç³»ç»´æŠ¤å’Œé—®å€™è¯æœ¯ï¼ˆè‡³å°‘300å­—ï¼‰ï¼šæ¸©æš–çš„é—®å€™å’Œå…³æ€€ï¼Œå›é¡¾ä¸Šæ¬¡æ²Ÿé€šçš„è¦ç‚¹ï¼Œå±•ç°å¯¹{customer_name}å’Œå…¶{customer_industry}ä¸šåŠ¡çš„æŒç»­å…³æ³¨",
            "value_reminder": "ä»·å€¼æé†’å’Œæ”¶ç›Šå¼ºåŒ–è¯æœ¯ï¼ˆè‡³å°‘400å­—ï¼‰ï¼šé‡æ–°å¼ºè°ƒè§£å†³æ–¹æ¡ˆçš„ä»·å€¼å’Œæ”¶ç›Šï¼Œåˆ†äº«æ–°çš„è¡Œä¸šæ´å¯Ÿã€æˆåŠŸæ¡ˆä¾‹æˆ–äº§å“æ›´æ–°ï¼Œä¿æŒå®¢æˆ·çš„å…´è¶£å’Œè®¤çŸ¥",
            "progress_update": "è¿›å±•æ›´æ–°å’Œæ¡ˆä¾‹åˆ†äº«è¯æœ¯ï¼ˆè‡³å°‘500å­—ï¼‰ï¼šåˆ†äº«å…¶ä»–å®¢æˆ·çš„å®æ–½è¿›å±•å’ŒæˆåŠŸæ¡ˆä¾‹ï¼Œç‰¹åˆ«æ˜¯åŒè¡Œä¸šæˆ–ç±»ä¼¼è§„æ¨¡çš„ä¼ä¸šæ¡ˆä¾‹ï¼Œå¢å¼ºå®¢æˆ·çš„ä¿¡å¿ƒ",
            "concern_addressing": "é¡¾è™‘å¤„ç†å’Œæ”¯æŒæä¾›è¯æœ¯ï¼ˆè‡³å°‘350å­—ï¼‰ï¼šä¸»åŠ¨äº†è§£å®¢æˆ·çš„æ–°é¡¾è™‘æˆ–å˜åŒ–ï¼Œæä¾›é¢å¤–çš„æ”¯æŒå’Œè§£å†³æ–¹æ¡ˆï¼Œå±•ç°ä¸“ä¸šçš„æœåŠ¡æ€åº¦",
            "next_engagement": "ä¸‹æ¬¡äº’åŠ¨å’Œæ¨è¿›å®‰æ’è¯æœ¯ï¼ˆè‡³å°‘250å­—ï¼‰ï¼šå®‰æ’ä¸‹æ¬¡æ²Ÿé€šæˆ–ä¼šè®®ï¼Œæ˜ç¡®è®®é¢˜å’Œç›®æ ‡ï¼Œä¿æŒé”€å”®è¿›ç¨‹çš„è¿ç»­æ€§å’Œæ¨è¿›åŠ›"
        }}"""
        else:  # opening, presentationç­‰å…¶ä»–æƒ…å†µ
            return f"""{{
            "opening": "é’ˆå¯¹{customer_name}çš„ä¸ªæ€§åŒ–å¼€åœºç™½ï¼ˆè‡³å°‘300å­—ï¼‰ï¼šè¯¦ç»†ä»‹ç»è‡ªå·±ã€å…¬å¸èƒŒæ™¯ã€ä¸“ä¸šèƒ½åŠ›ï¼Œç»“åˆå…¶{customer_industry}èƒŒæ™¯å’Œ{customer_position}ç‰¹ç‚¹ï¼ŒåŒ…å«å…·ä½“çš„è¡Œä¸šæ´å¯Ÿå’Œä¸ªäººä»·å€¼ä¸»å¼ ",
            "pain_point": "åŸºäº{customer_industry}è¡Œä¸šç‰¹ç‚¹çš„ç—›ç‚¹åˆ†æï¼ˆè‡³å°‘400å­—ï¼‰ï¼šæ·±å…¥åˆ†æ{customer_position}å¯èƒ½é¢ä¸´çš„å…·ä½“ä¸šåŠ¡ç—›ç‚¹ã€æŒ‘æˆ˜å’Œå›°æ‰°ï¼ŒåŒ…å«è¡Œä¸šè¶‹åŠ¿ã€å¸‚åœºå‹åŠ›ã€ç«äº‰ç¯å¢ƒç­‰å¤šç»´åº¦åˆ†æ",
            "solution": "è¯¦ç»†çš„è§£å†³æ–¹æ¡ˆä»‹ç»è¯æœ¯ï¼ˆè‡³å°‘500å­—ï¼‰ï¼šé’ˆå¯¹ä¸Šè¿°ç—›ç‚¹ï¼Œæä¾›å…·ä½“ã€è¯¦ç»†çš„è§£å†³æ–¹æ¡ˆä»‹ç»ï¼ŒåŒ…å«äº§å“/æœåŠ¡ç‰¹ç‚¹ã€å®æ–½æ–¹æ³•ã€é¢„æœŸæ•ˆæœã€æŠ€æœ¯ä¼˜åŠ¿ç­‰å…¨é¢è¯´æ˜",
            "social_proof": "ä¸°å¯Œçš„ç¤¾ä¼šè¯æ˜å†…å®¹ï¼ˆè‡³å°‘350å­—ï¼‰ï¼šæä¾›è¯¦ç»†çš„æˆåŠŸæ¡ˆä¾‹ã€å®¢æˆ·è§è¯ã€æ•°æ®æ”¯æ’‘ã€è¡Œä¸šè®¤å¯ç­‰ï¼ŒåŒ…å«å…·ä½“çš„æ•°å­—ã€æ—¶é—´ã€æ•ˆæœæè¿°ï¼Œå¢å¼ºå¯ä¿¡åº¦å’Œè¯´æœåŠ›",
            "next_step": "æ˜ç¡®çš„ä¸‹ä¸€æ­¥è¡ŒåŠ¨è®¡åˆ’ï¼ˆè‡³å°‘250å­—ï¼‰ï¼šè¯¦ç»†çš„è·Ÿè¿›æ­¥éª¤ï¼ŒåŒ…æ‹¬ä¼šè®®å®‰æ’ã€æ–¹æ¡ˆæ¼”ç¤ºã€è¯•ç”¨ä½“éªŒã€åˆä½œæµç¨‹ç­‰å…·ä½“å®‰æ’å’Œæ—¶é—´èŠ‚ç‚¹"
        }}"""
    
    def _get_situation_guidance(self, script_type: str, methodology: str) -> str:
        """æ ¹æ®é”€å”®æƒ…å†µå’Œæ–¹æ³•è®ºæä¾›å…·ä½“æŒ‡å¯¼"""
        guidance_map = {
            'initial_contact': {
                'general': 'è¿™æ˜¯åˆæ¬¡æ¥è§¦å®¢æˆ·ï¼Œé‡ç‚¹æ˜¯å»ºç«‹ä¿¡ä»»å’Œå¼•èµ·å…´è¶£ã€‚å¼€åœºç™½è¦ç®€æ´æœ‰åŠ›ï¼Œå¿«é€Ÿå±•ç¤ºä»·å€¼ã€‚',
                'spin': 'ä½¿ç”¨SPINæ–¹æ³•ï¼Œå…ˆäº†è§£å®¢æˆ·çš„ç°çŠ¶(Situation)ï¼Œç„¶åé€æ­¥æŒ–æ˜é—®é¢˜ã€‚',
                'challenger': 'é‡‡ç”¨æŒ‘æˆ˜è€…æ–¹å¼ï¼Œæä¾›æ–°çš„è¡Œä¸šæ´å¯Ÿæ¥å¸å¼•å®¢æˆ·æ³¨æ„ã€‚',
                'consultative': 'ä»¥é¡¾é—®èº«ä»½å‡ºç°ï¼Œå±•ç°ä¸“ä¸šæ€§å’Œå¯¹å®¢æˆ·è¡Œä¸šçš„æ·±åº¦ç†è§£ã€‚'
            },
            'opening': {
                'general': 'å¼€åœºç™½é˜¶æ®µï¼Œéœ€è¦åœ¨30ç§’å†…æŠ“ä½å®¢æˆ·æ³¨æ„åŠ›ï¼Œå»ºç«‹åˆæ­¥ä¿¡ä»»ã€‚',
                'straightLine': 'ç›´æ¥åˆ‡å…¥ä¸»é¢˜ï¼Œæ˜ç¡®è¡¨è¾¾æ¥æ„å’Œä»·å€¼ä¸»å¼ ã€‚',
                'spin': 'ä»äº†è§£å®¢æˆ·ç°çŠ¶å¼€å§‹ï¼Œé¿å…ç›´æ¥æ¨é”€ã€‚',
                'challenger': 'åˆ†äº«è¡Œä¸šè¶‹åŠ¿æˆ–æŒ‘æˆ˜å®¢æˆ·ç°æœ‰è®¤çŸ¥ã€‚'
            },
            'discovery': {
                 'general': 'éœ€æ±‚æŒ–æ˜é˜¶æ®µï¼Œé‡ç‚¹æ˜¯æ·±å…¥äº†è§£å®¢æˆ·ç—›ç‚¹å’Œéœ€æ±‚ã€‚',
                 'spin': 'ç³»ç»Ÿæ€§åœ°é—®SPINå››ç±»é—®é¢˜ï¼šæƒ…å†µã€é—®é¢˜ã€å½±å“ã€éœ€æ±‚å›æŠ¥ã€‚',
                 'consultative': 'åƒé¡¾é—®ä¸€æ ·æ·±åº¦è¯Šæ–­å®¢æˆ·ä¸šåŠ¡é—®é¢˜ã€‚',
                 'solution': 'ä¸“æ³¨äºå‘ç°å®¢æˆ·çš„ä¸šåŠ¡æŒ‘æˆ˜å’Œæ”¹è¿›æœºä¼šã€‚'
             },
             'needs_discovery': {
                 'general': 'éœ€æ±‚æŒ–æ˜é˜¶æ®µï¼Œé‡ç‚¹æ˜¯æ·±å…¥äº†è§£å®¢æˆ·ç—›ç‚¹å’Œéœ€æ±‚ã€‚',
                 'spin': 'ç³»ç»Ÿæ€§åœ°é—®SPINå››ç±»é—®é¢˜ï¼šæƒ…å†µã€é—®é¢˜ã€å½±å“ã€éœ€æ±‚å›æŠ¥ã€‚',
                 'consultative': 'åƒé¡¾é—®ä¸€æ ·æ·±åº¦è¯Šæ–­å®¢æˆ·ä¸šåŠ¡é—®é¢˜ã€‚',
                 'solution': 'ä¸“æ³¨äºå‘ç°å®¢æˆ·çš„ä¸šåŠ¡æŒ‘æˆ˜å’Œæ”¹è¿›æœºä¼šã€‚'
             },
            'pain_point_discovery': {
                'general': 'ç—›ç‚¹æŒ–æ˜é˜¶æ®µï¼Œè¦è®©å®¢æˆ·æ„è¯†åˆ°é—®é¢˜çš„ä¸¥é‡æ€§å’Œç´§è¿«æ€§ã€‚',
                'challenger': 'æ•™è‚²å®¢æˆ·ä»–ä»¬å¯èƒ½æ²¡æœ‰æ„è¯†åˆ°çš„é—®é¢˜ã€‚',
                'spin': 'é€šè¿‡å½±å“æ€§é—®é¢˜è®©å®¢æˆ·æ„Ÿå—åˆ°é—®é¢˜çš„åæœã€‚',
                'value': 'é‡åŒ–é—®é¢˜å¯¹å®¢æˆ·ä¸šåŠ¡çš„å½±å“ã€‚'
            },
            'presentation': {
                'general': 'æ–¹æ¡ˆå±•ç¤ºé˜¶æ®µï¼Œè¦å°†è§£å†³æ–¹æ¡ˆä¸å®¢æˆ·å…·ä½“éœ€æ±‚ç´§å¯†å…³è”ã€‚',
                'solution': 'å±•ç¤ºç»¼åˆè§£å†³æ–¹æ¡ˆå¦‚ä½•è§£å†³å®¢æˆ·çš„ä¸šåŠ¡é—®é¢˜ã€‚',
                'value': 'é‡ç‚¹å¼ºè°ƒROIå’Œä¸šåŠ¡ä»·å€¼ã€‚',
                'consultative': 'ä»¥ä¸“ä¸šå»ºè®®çš„æ–¹å¼æ¨èè§£å†³æ–¹æ¡ˆã€‚'
            },
            'objection_handling': {
                'general': 'å¼‚è®®å¤„ç†é˜¶æ®µï¼Œè¦ç†è§£å¼‚è®®èƒŒåçš„çœŸå®æ‹…å¿§ï¼Œå¹¶æä¾›æœ‰è¯´æœåŠ›çš„å›åº”ã€‚',
                'challenger': 'ç”¨æ•°æ®å’Œæ¡ˆä¾‹æŒ‘æˆ˜å®¢æˆ·çš„æ‹…å¿§ã€‚',
                'consultative': 'ç«™åœ¨å®¢æˆ·è§’åº¦åˆ†æå¼‚è®®çš„åˆç†æ€§ã€‚',
                'value': 'ç”¨ROIåˆ†æåŒ–è§£ä»·æ ¼å¼‚è®®ã€‚'
            },
            'closing': {
                'general': 'æˆäº¤ä¿ƒæˆé˜¶æ®µï¼Œè¦åˆ›é€ ç´§è¿«æ„Ÿå¹¶æ˜ç¡®ä¸‹ä¸€æ­¥è¡ŒåŠ¨ã€‚',
                'straightLine': 'ç›´æ¥è¦æ±‚æˆäº¤ï¼Œä¸æ‹–æ³¥å¸¦æ°´ã€‚',
                'challenger': 'åŸºäºå‰é¢å»ºç«‹çš„ä»·å€¼è®¤çŸ¥æ¨åŠ¨å†³ç­–ã€‚',
                'solution': 'å¼ºè°ƒè§£å†³æ–¹æ¡ˆçš„å®Œæ•´æ€§å’Œå®æ–½çš„é‡è¦æ€§ã€‚'
            },
            'follow_up': {
                'general': 'è·Ÿè¿›é˜¶æ®µï¼Œè¦ä¿æŒå®¢æˆ·å…´è¶£å¹¶æ¨è¿›é”€å”®è¿›ç¨‹ã€‚',
                'consultative': 'æä¾›é¢å¤–çš„ä¸“ä¸šè§è§£å’Œå»ºè®®ã€‚',
                'value': 'åˆ†äº«æ›´å¤šä»·å€¼è¯æ˜å’ŒæˆåŠŸæ¡ˆä¾‹ã€‚',
                'challenger': 'æŒç»­æ•™è‚²å®¢æˆ·ï¼Œå¼ºåŒ–ä»·å€¼è®¤çŸ¥ã€‚'
            }
        }
        
        situation_guidance = guidance_map.get(script_type, {})
        specific_guidance = situation_guidance.get(methodology, situation_guidance.get('general', ''))
        
        return f"é”€å”®æƒ…å†µæŒ‡å¯¼ï¼š{specific_guidance}"
    
    def _get_methodology_detailed_guidance(self, methodology: str) -> str:
        """è·å–é”€å”®æ–¹æ³•è®ºçš„è¯¦ç»†å®æ–½æŒ‡å¯¼"""
        methodology_details = {
            'straightLine': '''
é”€å”®æ–¹æ³•è®ºè¯¦ç»†æŒ‡å¯¼ - åå°”è¡—ä¹‹ç‹¼ç›´çº¿é”€å”®æ³•ï¼š
æ ¸å¿ƒåŸåˆ™ï¼š
1. ç›´æ¥æ€§ï¼šå¼€é—¨è§å±±ï¼Œä¸ç»•å¼¯å­ï¼Œç›´æ¥è¡¨è¾¾æ¥æ„å’Œä»·å€¼
2. æ§åˆ¶æ€§ï¼šä¸»å¯¼å¯¹è¯èŠ‚å¥ï¼Œå¼•å¯¼å®¢æˆ·æŒ‰ç…§ä½ çš„é€»è¾‘æ€è€ƒ
3. ç´§è¿«æ€§ï¼šåˆ›é€ æ—¶é—´å‹åŠ›ï¼Œå¼ºè°ƒæœºä¼šçš„ç¨€ç¼ºæ€§å’Œæ—¶æ•ˆæ€§
4. ç¡®å®šæ€§ï¼šå±•ç°ç»å¯¹çš„è‡ªä¿¡ï¼Œè®©å®¢æˆ·æ„Ÿå—åˆ°ä½ çš„ä¸“ä¸šå’Œæƒå¨

è¯æœ¯è¦æ±‚ï¼š
- å¼€åœºç™½ï¼š30ç§’å†…å»ºç«‹æƒå¨ï¼Œç›´æ¥è¯´æ˜æ¥æ„
- ç—›ç‚¹æŒ–æ˜ï¼šå¿«é€Ÿè¯†åˆ«æ ¸å¿ƒé—®é¢˜ï¼Œä¸è¦è¿‡åº¦åˆ†æ
- è§£å†³æ–¹æ¡ˆï¼šç®€æ´æœ‰åŠ›åœ°å±•ç¤ºä»·å€¼ï¼Œé¿å…æŠ€æœ¯ç»†èŠ‚
- æˆäº¤ä¿ƒæˆï¼šç›´æ¥è¦æ±‚å†³ç­–ï¼Œä¸ç»™çŠ¹è±«æ—¶é—´
- è¯­è¨€é£æ ¼ï¼šåšå®šã€è‡ªä¿¡ã€æœ‰è¯´æœåŠ›''',
            
            'spin': '''
é”€å”®æ–¹æ³•è®ºè¯¦ç»†æŒ‡å¯¼ - SPINé”€å”®æ³•ï¼š
æ ¸å¿ƒå››æ­¥éª¤ï¼š
1. Situation Questions (æƒ…å†µé—®é¢˜)ï¼šäº†è§£å®¢æˆ·ç°çŠ¶ï¼Œå»ºç«‹èƒŒæ™¯
   - "è¯·ä»‹ç»ä¸€ä¸‹è´µå…¬å¸ç›®å‰çš„...æƒ…å†µï¼Ÿ"
   - "æ‚¨ç°åœ¨æ˜¯å¦‚ä½•å¤„ç†...çš„ï¼Ÿ"

2. Problem Questions (é—®é¢˜é—®é¢˜)ï¼šå‘ç°ç—›ç‚¹å’Œä¸æ»¡
   - "åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­é‡åˆ°ä»€ä¹ˆå›°éš¾ï¼Ÿ"
   - "è¿™ç§æ–¹å¼æœ‰ä»€ä¹ˆä¸è¶³ä¹‹å¤„ï¼Ÿ"

3. Implication Questions (å½±å“é—®é¢˜)ï¼šæ”¾å¤§é—®é¢˜çš„åæœ
   - "è¿™ä¸ªé—®é¢˜å¯¹ä¸šåŠ¡æœ‰ä»€ä¹ˆå½±å“ï¼Ÿ"
   - "å¦‚æœä¸è§£å†³ï¼Œå¯èƒ½ä¼šå¯¼è‡´ä»€ä¹ˆåæœï¼Ÿ"

4. Need-payoff Questions (éœ€æ±‚å›æŠ¥é—®é¢˜)ï¼šè®©å®¢æˆ·è¯´å‡ºè§£å†³æ–¹æ¡ˆçš„ä»·å€¼
   - "å¦‚æœèƒ½è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå¯¹æ‚¨æ„å‘³ç€ä»€ä¹ˆï¼Ÿ"
   - "è¿™æ ·çš„æ”¹è¿›ä¼šå¸¦æ¥ä»€ä¹ˆå¥½å¤„ï¼Ÿ"

è¯æœ¯ç‰¹ç‚¹ï¼šä»¥é—®é¢˜ä¸ºå¯¼å‘ï¼Œè®©å®¢æˆ·è‡ªå·±è¯´å‡ºéœ€æ±‚å’Œä»·å€¼''',
            
            'challenger': '''
é”€å”®æ–¹æ³•è®ºè¯¦ç»†æŒ‡å¯¼ - æŒ‘æˆ˜è€…é”€å”®æ³•ï¼š
æ ¸å¿ƒä¸‰æ­¥éª¤ï¼š
1. Teach (æ•™å¯¼)ï¼šæä¾›æ–°çš„è¡Œä¸šæ´å¯Ÿï¼ŒæŒ‘æˆ˜å®¢æˆ·ç°æœ‰è®¤çŸ¥
   - åˆ†äº«è¡Œä¸šè¶‹åŠ¿å’Œæœ€ä½³å®è·µ
   - æŒ‡å‡ºå®¢æˆ·å¯èƒ½å¿½è§†çš„é—®é¢˜
   - ç”¨æ•°æ®å’Œæ¡ˆä¾‹æ”¯æ’‘è§‚ç‚¹

2. Tailor (å®šåˆ¶)ï¼šå°†æ´å¯Ÿä¸å®¢æˆ·å…·ä½“æƒ…å†µç»“åˆ
   - åˆ†æå®¢æˆ·çš„ç‹¬ç‰¹æŒ‘æˆ˜
   - å±•ç¤ºè§£å†³æ–¹æ¡ˆçš„é’ˆå¯¹æ€§ä»·å€¼
   - é‡åŒ–æ”¹è¿›çš„æ½œåœ¨æ”¶ç›Š

3. Take Control (æ§åˆ¶)ï¼šä¸»å¯¼é”€å”®è¿›ç¨‹ï¼Œæ¨åŠ¨å†³ç­–
   - åˆ›é€ ç´§è¿«æ„Ÿ
   - æ˜ç¡®ä¸‹ä¸€æ­¥è¡ŒåŠ¨
   - ä¸å¦¥åäºå®¢æˆ·çš„æ‹–å»¶

è¯æœ¯ç‰¹ç‚¹ï¼šæƒå¨ã€æ•™è‚²æ€§ã€æ•°æ®é©±åŠ¨ï¼Œæ•¢äºæŒ‘æˆ˜å®¢æˆ·æƒ³æ³•''',
            
            'consultative': '''
é”€å”®æ–¹æ³•è®ºè¯¦ç»†æŒ‡å¯¼ - é¡¾é—®å¼é”€å”®æ³•ï¼š
æ ¸å¿ƒç†å¿µï¼šä»¥é¡¾é—®èº«ä»½ä¸å®¢æˆ·åˆä½œï¼Œè€Œéä¼ ç»Ÿçš„é”€å”®å…³ç³»

å®æ–½æ­¥éª¤ï¼š
1. å»ºç«‹ä¿¡ä»»ï¼šå±•ç°ä¸“ä¸šæ€§å’Œå¯¹å®¢æˆ·è¡Œä¸šçš„æ·±åº¦ç†è§£
2. æ·±åº¦è¯Šæ–­ï¼šåƒåŒ»ç”Ÿä¸€æ ·å…¨é¢äº†è§£å®¢æˆ·çš„ä¸šåŠ¡çŠ¶å†µ
3. åä½œåˆ†æï¼šä¸å®¢æˆ·ä¸€èµ·åˆ†æé—®é¢˜çš„æ ¹æœ¬åŸå› 
4. å…±åŒåˆ¶å®šè§£å†³æ–¹æ¡ˆï¼šè®©å®¢æˆ·å‚ä¸æ–¹æ¡ˆè®¾è®¡è¿‡ç¨‹
5. é•¿æœŸä¼™ä¼´å…³ç³»ï¼šå…³æ³¨å®¢æˆ·é•¿æœŸæˆåŠŸï¼Œè€Œéå•æ¬¡äº¤æ˜“

è¯æœ¯ç‰¹ç‚¹ï¼š
- ä½¿ç”¨ä¸“ä¸šæœ¯è¯­å’Œè¡Œä¸šæ´å¯Ÿ
- æå‡ºæ·±åº¦çš„è¯Šæ–­æ€§é—®é¢˜
- åˆ†äº«ç›¸å…³ç»éªŒå’Œæœ€ä½³å®è·µ
- è¯­è°ƒè°¦é€Šä½†ä¸“ä¸šï¼Œé¿å…æ¨é”€æ„Ÿ''',
            
            'solution': '''
é”€å”®æ–¹æ³•è®ºè¯¦ç»†æŒ‡å¯¼ - è§£å†³æ–¹æ¡ˆé”€å”®æ³•ï¼š
æ ¸å¿ƒç†å¿µï¼šä¸“æ³¨äºè§£å†³å®¢æˆ·çš„ä¸šåŠ¡é—®é¢˜ï¼Œè€Œéé”€å”®äº§å“

å®æ–½æ¡†æ¶ï¼š
1. ä¸šåŠ¡é—®é¢˜è¯Šæ–­ï¼š
   - æ·±å…¥äº†è§£å®¢æˆ·çš„ä¸šåŠ¡æµç¨‹
   - è¯†åˆ«æ•ˆç‡ç“¶é¢ˆå’Œæ”¹è¿›æœºä¼š
   - åˆ†æé—®é¢˜å¯¹ä¸šåŠ¡çš„å½±å“

2. ç»¼åˆè§£å†³æ–¹æ¡ˆè®¾è®¡ï¼š
   - æ•´åˆå¤šç§èµ„æºå’Œèƒ½åŠ›
   - æä¾›ç«¯åˆ°ç«¯çš„è§£å†³æ–¹æ¡ˆ
   - è€ƒè™‘å®æ–½çš„å¯è¡Œæ€§å’Œé£é™©

3. ä»·å€¼é‡åŒ–ï¼š
   - è®¡ç®—ROIå’Œæˆæœ¬èŠ‚çº¦
   - å±•ç¤ºä¸šåŠ¡æ”¹è¿›çš„å…·ä½“æŒ‡æ ‡
   - æä¾›å®æ–½æ—¶é—´è¡¨å’Œé‡Œç¨‹ç¢‘

4. å®æ–½æ”¯æŒï¼š
   - è¯¦ç»†çš„å®æ–½è®¡åˆ’
   - æŒç»­çš„ä¼˜åŒ–å’Œæ”¯æŒ
   - æˆåŠŸæ¡ˆä¾‹å’Œå‚è€ƒ

è¯æœ¯ç‰¹ç‚¹ï¼šç³»ç»Ÿæ€§ã€å…¨é¢æ€§ã€æ³¨é‡ä¸šåŠ¡ä»·å€¼å’Œå®æ–½ç»†èŠ‚''',
            
            'value': '''
é”€å”®æ–¹æ³•è®ºè¯¦ç»†æŒ‡å¯¼ - ä»·å€¼é”€å”®æ³•ï¼š
æ ¸å¿ƒç†å¿µï¼šå§‹ç»ˆå›´ç»•å®¢æˆ·èƒ½è·å¾—çš„ä»·å€¼æ¥æ„å»ºé”€å”®å¯¹è¯

ä»·å€¼å±•ç¤ºæ¡†æ¶ï¼š
1. ä»·å€¼å‘ç°ï¼š
   - äº†è§£å®¢æˆ·çš„æˆåŠŸæŒ‡æ ‡
   - è¯†åˆ«å½“å‰çš„æˆæœ¬å’ŒæŸå¤±
   - å‘ç°æœªå®ç°çš„æœºä¼š

2. ä»·å€¼é‡åŒ–ï¼š
   - è®¡ç®—å…·ä½“çš„è´¢åŠ¡æ”¶ç›Š
   - åˆ†ææˆæœ¬èŠ‚çº¦çš„æ½œåŠ›
   - è¯„ä¼°æ•ˆç‡æå‡çš„ä»·å€¼

3. ä»·å€¼è¯æ˜ï¼š
   - æä¾›è¯¦ç»†çš„ROIåˆ†æ
   - åˆ†äº«ç±»ä¼¼å®¢æˆ·çš„æˆåŠŸæ¡ˆä¾‹
   - å±•ç¤ºå¯è¡¡é‡çš„ä¸šåŠ¡æˆæœ

4. ä»·å€¼å®ç°ï¼š
   - åˆ¶å®šä»·å€¼å®ç°çš„è·¯å¾„
   - è®¾å®šå¯è¿½è¸ªçš„æˆåŠŸæŒ‡æ ‡
   - æ‰¿è¯ºæŒç»­çš„ä»·å€¼ä¼˜åŒ–

è¯æœ¯ç‰¹ç‚¹ï¼šæ•°æ®é©±åŠ¨ã€é‡åŒ–åˆ†æã€å¼ºè°ƒæŠ•èµ„å›æŠ¥å’Œä¸šåŠ¡æˆæœ'''
        }
        
        return methodology_details.get(methodology, f"é”€å”®æ–¹æ³•è®ºï¼š{methodology}ï¼ˆè¯·æŒ‰ç…§è¯¥æ–¹æ³•çš„æ ¸å¿ƒåŸåˆ™è¿›è¡Œè¯æœ¯è®¾è®¡ï¼‰")
    
    def _get_content_focus(self, script_type: str) -> str:
        """æ ¹æ®é”€å”®æƒ…å†µæä¾›å†…å®¹é‡ç‚¹æŒ‡å¯¼"""
        focus_map = {
            'opening': """
å†…å®¹é‡ç‚¹è¦æ±‚ï¼š
- opening: å¿…é¡»æ˜¯ç®€çŸ­æœ‰åŠ›çš„è‡ªæˆ‘ä»‹ç»å’Œä»·å€¼ä¸»å¼ ï¼Œ30ç§’å†…æŠ“ä½æ³¨æ„åŠ›
- pain_point: æå‡ºè¡Œä¸šæ™®éé—®é¢˜ï¼Œå¼•èµ·å®¢æˆ·æ€è€ƒï¼Œä¸è¦è¿‡äºæ·±å…¥
- solution: ç®€è¦æ¦‚è¿°è§£å†³æ–¹æ¡ˆçš„æ ¸å¿ƒä»·å€¼ï¼Œæ¿€å‘å…´è¶£è€Œéè¯¦ç»†ä»‹ç»
- social_proof: æåŠçŸ¥åå®¢æˆ·æˆ–ç®€å•æ•°æ®ï¼Œå»ºç«‹åˆæ­¥ä¿¡ä»»
- next_step: è¯·æ±‚çŸ­æ—¶é—´ä¼šé¢æˆ–ç”µè¯æ²Ÿé€šçš„æœºä¼š""",
            
            'needs_discovery': """
å†…å®¹é‡ç‚¹è¦æ±‚ï¼š
- opening: å›é¡¾ä¹‹å‰æ¥è§¦ï¼Œè¡¨è¾¾å¯¹å®¢æˆ·ä¸šåŠ¡çš„å…³æ³¨å’Œç†è§£
- pain_point: æ·±åº¦æŒ–æ˜å…·ä½“ç—›ç‚¹ï¼Œä½¿ç”¨å¼€æ”¾æ€§é—®é¢˜å¼•å¯¼å®¢æˆ·è¡¨è¾¾
- solution: ä¸è¦è¯¦ç»†ä»‹ç»äº§å“ï¼Œè€Œæ˜¯å±•ç¤ºç†è§£å®¢æˆ·éœ€æ±‚çš„èƒ½åŠ›
- social_proof: åˆ†äº«ç±»ä¼¼å®¢æˆ·é¢ä¸´ç›¸åŒæŒ‘æˆ˜çš„æ¡ˆä¾‹
- next_step: æè®®æ·±å…¥éœ€æ±‚åˆ†æä¼šè®®æˆ–ç°åœºè°ƒç ”""",
            
            'presentation': """
å†…å®¹é‡ç‚¹è¦æ±‚ï¼š
- opening: ç¡®è®¤å®¢æˆ·éœ€æ±‚ï¼Œä¸ºæ–¹æ¡ˆå±•ç¤ºåšé“ºå«
- pain_point: æ€»ç»“ä¹‹å‰å‘ç°çš„å…³é”®ç—›ç‚¹ï¼Œè·å¾—å®¢æˆ·ç¡®è®¤
- solution: è¯¦ç»†å±•ç¤ºè§£å†³æ–¹æ¡ˆå¦‚ä½•è§£å†³æ¯ä¸ªå…·ä½“ç—›ç‚¹ï¼ŒåŒ…å«åŠŸèƒ½å’Œæ•ˆæœ
- social_proof: æä¾›è¯¦ç»†çš„æˆåŠŸæ¡ˆä¾‹å’ŒROIæ•°æ®
- next_step: æè®®è¯•ç”¨ã€æ¼”ç¤ºæˆ–è¯¦ç»†æ–¹æ¡ˆè®¨è®º""",
            
            'objection_handling': """
å†…å®¹é‡ç‚¹è¦æ±‚ï¼š
- opening: ç†è§£å¹¶è®¤åŒå®¢æˆ·çš„æ‹…å¿§ï¼Œè¡¨ç°å‡ºä¸“ä¸šå’Œè€å¿ƒ
- pain_point: åˆ†æä¸è§£å†³é—®é¢˜çš„é£é™©å’Œæœºä¼šæˆæœ¬
- solution: é’ˆå¯¹å…·ä½“å¼‚è®®æä¾›æœ‰è¯´æœåŠ›çš„å›åº”å’Œæ›¿ä»£æ–¹æ¡ˆ
- social_proof: åˆ†äº«ç±»ä¼¼å¼‚è®®å®¢æˆ·æœ€ç»ˆæˆåŠŸçš„æ¡ˆä¾‹
- next_step: æä¾›è¯•ç”¨æœŸã€åˆ†é˜¶æ®µå®æ–½æˆ–å…¶ä»–é™ä½é£é™©çš„æ–¹æ¡ˆ""",
            
            'closing': """
å†…å®¹é‡ç‚¹è¦æ±‚ï¼š
- opening: æ€»ç»“å‰æœŸæ²Ÿé€šæˆæœï¼Œç¡®è®¤å®¢æˆ·å¯¹ä»·å€¼çš„è®¤åŒ
- pain_point: å¼ºè°ƒä¸ç«‹å³è¡ŒåŠ¨çš„æœºä¼šæˆæœ¬å’Œç«äº‰é£é™©
- solution: å¼ºè°ƒè§£å†³æ–¹æ¡ˆçš„ç´§è¿«æ€§å’Œç‹¬ç‰¹ä¼˜åŠ¿
- social_proof: å±•ç¤ºå…¶ä»–å®¢æˆ·å¿«é€Ÿå†³ç­–åè·å¾—çš„æ”¶ç›Š
- next_step: æ˜ç¡®è¦æ±‚ç­¾çº¦æˆ–æ‰¿è¯ºï¼Œæä¾›é™æ—¶ä¼˜æƒ æˆ–æ¿€åŠ±""",
            
            'follow_up': """
å†…å®¹é‡ç‚¹è¦æ±‚ï¼š
- opening: è·Ÿè¿›ä¹‹å‰çš„æ‰¿è¯ºæˆ–è®¨è®ºï¼Œå±•ç°æŒç»­å…³æ³¨
- pain_point: äº†è§£å®¢æˆ·å½“å‰çŠ¶å†µå˜åŒ–ï¼Œå‘ç°æ–°çš„éœ€æ±‚ç‚¹
- solution: æä¾›é¢å¤–ä»·å€¼æˆ–ä¼˜åŒ–å»ºè®®ï¼Œä¿æŒå®¢æˆ·å…´è¶£
- social_proof: åˆ†äº«æœ€æ–°çš„æˆåŠŸæ¡ˆä¾‹æˆ–è¡Œä¸šè¶‹åŠ¿
- next_step: æ¨è¿›åˆ°ä¸‹ä¸€ä¸ªé”€å”®é˜¶æ®µæˆ–ç»´æŠ¤å®¢æˆ·å…³ç³»"""
        }
        
        return focus_map.get(script_type, "")
    
    def _build_advanced_settings_guidance(self, advanced_settings: Dict[str, Any]) -> str:
        """æ„å»ºé«˜çº§è®¾ç½®æŒ‡å¯¼"""
        if not advanced_settings:
            return ""
        
        guidance_parts = []
        
        # è§’è‰²è®¾ç½®å¤„ç†
        if 'roleSettings' in advanced_settings:
            role_settings = advanced_settings['roleSettings']
            
            # èŒä¸šèº«ä»½
            if 'professionalRole' in role_settings:
                role = role_settings['professionalRole']
                role_guidance = {
                    'brand_consultant': 'ä»¥å“ç‰Œå‡çº§ä¸“å®¶çš„èº«ä»½ï¼Œé‡ç‚¹å…³æ³¨å“ç‰Œä»·å€¼æå‡å’Œå¸‚åœºå®šä½ä¼˜åŒ–',
                    'marketing_specialist': 'ä»¥å¸‚åœºè¥é”€ä¸“å®¶çš„èº«ä»½ï¼Œä¸“æ³¨äºè¥é”€ç­–ç•¥å’Œå®¢æˆ·è·å–',
                    'sales_director': 'ä»¥é”€å”®æ€»ç›‘çš„èº«ä»½ï¼Œå¼ºè°ƒé”€å”®æµç¨‹ä¼˜åŒ–å’Œä¸šç»©æå‡',
                    'business_consultant': 'ä»¥å•†ä¸šé¡¾é—®çš„èº«ä»½ï¼Œæä¾›å…¨é¢çš„ä¸šåŠ¡å‘å±•å»ºè®®',
                    'strategy_advisor': 'ä»¥æˆ˜ç•¥é¡¾é—®çš„èº«ä»½ï¼Œä¸“æ³¨äºé•¿æœŸæˆ˜ç•¥è§„åˆ’å’Œç«äº‰ä¼˜åŠ¿'
                }
                if role in role_guidance:
                    guidance_parts.append(f"ä¸“ä¸šèº«ä»½ï¼š{role_guidance[role]}")
                elif role_settings.get('customRole'):
                    guidance_parts.append(f"ä¸“ä¸šèº«ä»½ï¼šä»¥{role_settings['customRole']}çš„èº«ä»½æä¾›ä¸“ä¸šæœåŠ¡")
            
            # æ•™è‚²èƒŒæ™¯
            if 'educationBackground' in role_settings:
                education = role_settings['educationBackground']
                education_guidance = {
                    'mba': 'è¿ç”¨MBAçº§åˆ«çš„å•†ä¸šåˆ†æèƒ½åŠ›å’Œæˆ˜ç•¥æ€ç»´',
                    'master': 'å±•ç°ç¡•å£«çº§åˆ«çš„ä¸“ä¸šæ·±åº¦å’Œç†è®ºåŸºç¡€',
                    'bachelor': 'ç»“åˆæœ¬ç§‘ä¸“ä¸šçŸ¥è¯†æä¾›å®ç”¨å»ºè®®',
                    'phd': 'è¿ç”¨åšå£«çº§åˆ«çš„ç ”ç©¶èƒ½åŠ›å’Œæ·±åº¦æ´å¯Ÿ'
                }
                if education in education_guidance:
                    guidance_parts.append(f"ä¸“ä¸šæ°´å¹³ï¼š{education_guidance[education]}")
                elif role_settings.get('customEducation'):
                    guidance_parts.append(f"ä¸“ä¸šæ°´å¹³ï¼šå…·å¤‡{role_settings['customEducation']}çš„ä¸“ä¸šèƒŒæ™¯")
            
            # ä»ä¸šç»éªŒ
            if 'experienceYears' in role_settings:
                experience = role_settings['experienceYears']
                experience_guidance = {
                    '1-3': 'ä»¥æ–°é”ä¸“å®¶çš„è§†è§’ï¼Œæä¾›åˆ›æ–°æ€è·¯å’Œæ•é”æ´å¯Ÿ',
                    '3-5': 'ç»“åˆä¸°å¯Œçš„å®æˆ˜ç»éªŒï¼Œæä¾›æˆç†Ÿå¯é çš„è§£å†³æ–¹æ¡ˆ',
                    '5-10': 'è¿ç”¨èµ„æ·±ä¸“å®¶çš„æ·±åº¦ç»éªŒï¼Œæä¾›æƒå¨æ€§å»ºè®®',
                    '10+': 'ä»¥è¡Œä¸šé¢†è¢–çš„é«˜åº¦ï¼Œæä¾›æˆ˜ç•¥æ€§æŒ‡å¯¼å’Œå‰ç»æ€§å»ºè®®'
                }
                if experience in experience_guidance:
                    guidance_parts.append(f"ç»éªŒæ°´å¹³ï¼š{experience_guidance[experience]}")
            
            # ä¸“ä¸šé¢†åŸŸ
            if 'expertiseArea' in role_settings:
                expertise = role_settings['expertiseArea']
                expertise_guidance = {
                    'brand_strategy': 'ä¸“æ³¨äºå“ç‰Œæˆ˜ç•¥è§„åˆ’å’Œå“ç‰Œä»·å€¼æå‡',
                    'market_analysis': 'æ“…é•¿å¸‚åœºåˆ†æå’Œç«äº‰ç¯å¢ƒè¯„ä¼°',
                    'business_optimization': 'ä¸“é•¿äºä¸šåŠ¡æµç¨‹ä¼˜åŒ–å’Œæ•ˆç‡æå‡',
                    'digital_transformation': 'ä¸“æ³¨äºæ•°å­—åŒ–è½¬å‹å’ŒæŠ€æœ¯åˆ›æ–°åº”ç”¨'
                }
                if expertise in expertise_guidance:
                    guidance_parts.append(f"ä¸“ä¸šé¢†åŸŸï¼š{expertise_guidance[expertise]}")
            
            # æœåŠ¡èŒƒå›´
            if 'services' in role_settings:
                services = role_settings['services']
                active_services = []
                service_names = {
                    'brandConsulting': 'å“ç‰Œå’¨è¯¢',
                    'strategyPlanning': 'æˆ˜ç•¥è§„åˆ’',
                    'marketAnalysis': 'å¸‚åœºåˆ†æ',
                    'businessOptimization': 'ä¸šåŠ¡ä¼˜åŒ–',
                    'teamTraining': 'å›¢é˜ŸåŸ¹è®­',
                    'digitalTransformation': 'æ•°å­—åŒ–è½¬å‹'
                }
                for service_key, service_name in service_names.items():
                    if services.get(service_key):
                        active_services.append(service_name)
                
                if active_services:
                    guidance_parts.append(f"æœåŠ¡èŒƒå›´ï¼šä¸“ä¸šæä¾›{' '.join(active_services)}ç­‰æœåŠ¡")
            
            # ä¸ªäººæˆå°±
            if role_settings.get('achievements'):
                guidance_parts.append(f"ä¸“ä¸šæˆå°±ï¼š{role_settings['achievements']}")
            
            # ä»·å€¼ä¸»å¼ 
            if role_settings.get('valueProposition'):
                guidance_parts.append(f"ä»·å€¼ä¸»å¼ ï¼š{role_settings['valueProposition']}")
        
        # è¯­è¨€é£æ ¼è®¾ç½®
        if 'languageStyle' in advanced_settings:
            style = advanced_settings['languageStyle']
            style_guidance = {
                'professional': 'ä½¿ç”¨æ­£å¼ã€ä¸“ä¸šçš„å•†åŠ¡è¯­è¨€ï¼Œé¿å…å£è¯­åŒ–è¡¨è¾¾',
                'friendly': 'é‡‡ç”¨å‹å¥½ã€äº²åˆ‡çš„è¯­è°ƒï¼Œæ‹‰è¿‘ä¸å®¢æˆ·çš„è·ç¦»',
                'confident': 'å±•ç°è‡ªä¿¡åšå®šçš„ä¸“ä¸šæ€åº¦ï¼Œä½¿ç”¨æƒå¨æ€§è¡¨è¾¾',
                'consultative': 'ä»¥é¡¾é—®èº«ä»½å‡ºç°ï¼Œæä¾›ä¸“ä¸šå»ºè®®å’Œæ´å¯Ÿ'
            }
            if style in style_guidance:
                guidance_parts.append(f"è¯­è¨€é£æ ¼ï¼š{style_guidance[style]}")
        
        # è¯æœ¯é•¿åº¦
        if 'scriptLength' in advanced_settings:
            length = advanced_settings['scriptLength']
            length_guidance = {
                1: 'ä¿æŒç®€æ´æ˜äº†ï¼Œé‡ç‚¹çªå‡ºæ ¸å¿ƒä¿¡æ¯',
                2: 'é€‚ä¸­é•¿åº¦ï¼Œå¹³è¡¡ä¿¡æ¯é‡å’Œå¯è¯»æ€§',
                3: 'è¯¦ç»†å…¨é¢ï¼Œæä¾›å……åˆ†çš„èƒŒæ™¯å’Œè®ºè¯'
            }
            if length in length_guidance:
                guidance_parts.append(f"å†…å®¹é•¿åº¦ï¼š{length_guidance[length]}")
        
        # åˆ›æ„ç¨‹åº¦
        if 'creativity' in advanced_settings:
            creativity = advanced_settings['creativity']
            if creativity <= 0.3:
                guidance_parts.append("åˆ›æ„ç¨‹åº¦ï¼šä¿æŒä¼ ç»Ÿç¨³é‡çš„è¡¨è¾¾æ–¹å¼ï¼Œæ³¨é‡å¯é æ€§")
            elif creativity <= 0.7:
                guidance_parts.append("åˆ›æ„ç¨‹åº¦ï¼šé€‚åº¦åˆ›æ–°ï¼Œå¹³è¡¡ä¼ ç»Ÿä¸æ–°é¢–çš„è¡¨è¾¾")
            else:
                guidance_parts.append("åˆ›æ„ç¨‹åº¦ï¼šé‡‡ç”¨åˆ›æ–°ç‹¬ç‰¹çš„è¡¨è¾¾æ–¹å¼ï¼Œçªå‡ºå·®å¼‚åŒ–")
        
        # è¡Œä¸šæœ¯è¯­
        if advanced_settings.get('industryTerms'):
            guidance_parts.append("ä¸“ä¸šæœ¯è¯­ï¼šé€‚å½“ä½¿ç”¨è¡Œä¸šä¸“ä¸šæœ¯è¯­ï¼Œå±•ç°ä¸“ä¸šæ€§")
        
        # ä¸ªäººç­¾å
        if advanced_settings.get('personalSignature'):
            guidance_parts.append(f"ä¸ªäººç‰¹è‰²ï¼š{advanced_settings['personalSignature']}")
        
        # è¾“å‡ºæ ¼å¼
        if 'outputFormat' in advanced_settings:
            format_type = advanced_settings['outputFormat']
            format_guidance = {
                'structured': 'é‡‡ç”¨ç»“æ„åŒ–æ ¼å¼ï¼Œæ¡ç†æ¸…æ™°',
                'conversational': 'ä½¿ç”¨å¯¹è¯å¼é£æ ¼ï¼Œè‡ªç„¶æµç•…',
                'bullet': 'ä½¿ç”¨è¦ç‚¹å¼è¡¨è¾¾ï¼Œç®€æ´æ˜äº†'
            }
            if format_type in format_guidance:
                guidance_parts.append(f"è¡¨è¾¾æ ¼å¼ï¼š{format_guidance[format_type]}")
        
        # æ²Ÿé€šæ¸ é“ä¼˜åŒ–
        if 'channelOptimization' in advanced_settings:
            channel = advanced_settings['channelOptimization']
            channel_guidance = {
                'phone': 'é’ˆå¯¹ç”µè¯æ²Ÿé€šä¼˜åŒ–ï¼Œæ³¨é‡è¯­éŸ³è¡¨è¾¾æ•ˆæœ',
                'email': 'é’ˆå¯¹é‚®ä»¶æ²Ÿé€šä¼˜åŒ–ï¼Œæ³¨é‡æ–‡å­—è¡¨è¾¾æ¸…æ™°',
                'meeting': 'é’ˆå¯¹é¢å¯¹é¢ä¼šè®®ä¼˜åŒ–ï¼Œæ³¨é‡äº’åŠ¨æ€§',
                'video': 'é’ˆå¯¹è§†é¢‘ä¼šè®®ä¼˜åŒ–ï¼Œå¹³è¡¡è§†è§‰å’Œè¯­éŸ³æ•ˆæœ'
            }
            if channel in channel_guidance:
                guidance_parts.append(f"æ²Ÿé€šæ¸ é“ï¼š{channel_guidance[channel]}")
        
        # æ—¶é—´æ•æ„Ÿæ€§
        if 'timeSensitivity' in advanced_settings:
            time_sensitivity = advanced_settings['timeSensitivity']
            time_guidance = {
                'urgent': 'å¼ºè°ƒç´§è¿«æ€§ï¼Œçªå‡ºç«‹å³è¡ŒåŠ¨çš„é‡è¦æ€§',
                'normal': 'ä¿æŒæ­£å¸¸èŠ‚å¥ï¼Œé€‚åº¦å¼•å¯¼å†³ç­–',
                'relaxed': 'ä¿æŒè€å¿ƒï¼Œé‡ç‚¹å»ºç«‹é•¿æœŸå…³ç³»'
            }
            if time_sensitivity in time_guidance:
                guidance_parts.append(f"æ—¶é—´èŠ‚å¥ï¼š{time_guidance[time_sensitivity]}")
        
        if guidance_parts:
            return "\n\né«˜çº§è®¾ç½®æŒ‡å¯¼ï¼š\n" + "\n".join([f"- {part}" for part in guidance_parts])
        
        return ""
    
    def test_connection(self, provider: str, model: str, api_key: str, base_url: str = None) -> Dict[str, Any]:
        """æµ‹è¯•AI APIè¿æ¥"""
        try:
            headers = {
                'Content-Type': 'application/json'
            }
            
            # æ ¹æ®ä¸åŒæä¾›å•†è®¾ç½®ä¸åŒçš„è®¤è¯æ–¹å¼å’Œæµ‹è¯•æ–¹æ³•
            if provider.lower() == 'gemini':
                # Geminiä½¿ç”¨API keyä½œä¸ºæŸ¥è¯¢å‚æ•°
                test_url = f"{base_url or 'https://generativelanguage.googleapis.com/v1beta'}/models"
                response = requests.get(test_url, params={'key': api_key}, timeout=10)
            elif provider.lower() == 'moonshot':
                # Moonshotä½¿ç”¨chat/completionsç«¯ç‚¹è¿›è¡Œæµ‹è¯•
                headers['Authorization'] = f'Bearer {api_key}'
                test_url = f"{base_url or 'https://api.moonshot.cn/v1'}/chat/completions"
                test_data = {
                    "model": model or "moonshot-v1-8k",
                    "messages": [{"role": "user", "content": "Hello"}],
                    "max_tokens": 5
                }
                response = requests.post(test_url, headers=headers, json=test_data, timeout=10)
            else:
                # å…¶ä»–æä¾›å•†ä½¿ç”¨Bearer tokenå’Œ/modelsç«¯ç‚¹
                headers['Authorization'] = f'Bearer {api_key}'
                test_url = f"{base_url or 'https://api.openai.com/v1'}/models"
                response = requests.get(test_url, headers=headers, timeout=10)
            
            if response.status_code == 200:
                return {'success': True, 'message': 'APIè¿æ¥æˆåŠŸ'}
            else:
                error_detail = ''
                try:
                    error_data = response.json()
                    error_detail = error_data.get('error', {}).get('message', '')
                except:
                    error_detail = response.text[:200] if response.text else ''
                return {'success': False, 'error': f'APIè¿”å›é”™è¯¯ {response.status_code}: {error_detail}'}
                
        except requests.exceptions.Timeout:
            return {'success': False, 'error': 'è¿æ¥è¶…æ—¶'}
        except requests.exceptions.ConnectionError:
            return {'success': False, 'error': 'æ— æ³•è¿æ¥åˆ°APIæœåŠ¡å™¨'}
        except Exception as e:
            return {'success': False, 'error': f'è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}'}
    
    def get_models_list(self, provider: str, api_key: str, base_url: str = None) -> Dict[str, Any]:
        """è·å–AIæ¨¡å‹åˆ—è¡¨"""
        try:
            headers = {
                'Content-Type': 'application/json'
            }
            
            # æ ¹æ®ä¸åŒæä¾›å•†è®¾ç½®ä¸åŒçš„è®¤è¯æ–¹å¼å’ŒURL
            if provider.lower() == 'gemini':
                models_url = f"{base_url or 'https://generativelanguage.googleapis.com/v1beta'}/models"
                response = requests.get(models_url, params={'key': api_key}, timeout=15)
            else:
                headers['Authorization'] = f'Bearer {api_key}'
                models_url = f"{base_url or 'https://api.openai.com/v1'}/models"
                response = requests.get(models_url, headers=headers, timeout=15)
            
            if response.status_code == 200:
                data = response.json()
                models = []
                
                # è§£æä¸åŒæä¾›å•†çš„å“åº”æ ¼å¼
                if provider.lower() == 'gemini':
                    # Gemini APIå“åº”æ ¼å¼
                    if 'models' in data:
                        for model in data['models']:
                            model_name = model.get('name', '').replace('models/', '')
                            if model_name:
                                models.append(model_name)
                else:
                    # OpenAIå…¼å®¹æ ¼å¼
                    if 'data' in data:
                        for model in data['data']:
                            model_id = model.get('id')
                            if model_id:
                                models.append(model_id)
                
                return {'success': True, 'models': models}
            else:
                return {'success': False, 'error': f'è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {response.status_code}'}
                
        except requests.exceptions.Timeout:
            return {'success': False, 'error': 'è¯·æ±‚è¶…æ—¶'}
        except requests.exceptions.ConnectionError:
            return {'success': False, 'error': 'æ— æ³•è¿æ¥åˆ°APIæœåŠ¡å™¨'}
        except Exception as e:
            return {'success': False, 'error': f'è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {str(e)}'}
    
    def update_model_mapping(self, provider: str, models: List[str]) -> Dict[str, Any]:
        """æ›´æ–°æ¨¡å‹æ˜ å°„è¡¨"""
        try:
            # æ ¹æ®æä¾›å•†ç¡®å®šé»˜è®¤æ˜ å°„çš„åç«¯æ¨¡å‹
            provider_mapping = {
                'xai': 'grok-4',
                'deepseek': 'deepseek-reasoner', 
                'moonshot': 'moonshot-kimi-k2',
                'openai': 'openai-gpt4',
                'gemini': 'gemini-pro'
            }
            
            backend_model = provider_mapping.get(provider.lower())
            if not backend_model:
                return {'success': False, 'error': f'ä¸æ”¯æŒçš„æä¾›å•†: {provider}'}
            
            # ä¸ºæ¯ä¸ªæ–°æ¨¡å‹åˆ›å»ºæ˜ å°„
            updated_mappings = []
            for model in models:
                mapping_key = f"{provider.lower()}:{model}"
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨æ˜ å°„
                if mapping_key not in self._map_model_name.__defaults__[0] if hasattr(self._map_model_name, '__defaults__') else {}:
                    # åŠ¨æ€æ·»åŠ æ–°çš„æ˜ å°„
                    updated_mappings.append({
                        'frontend': mapping_key,
                        'backend': backend_model,
                        'model': model
                    })
            
            # è¿™é‡Œå¯ä»¥å°†æ˜ å°„ä¿å­˜åˆ°é…ç½®æ–‡ä»¶æˆ–æ•°æ®åº“
            # ç›®å‰åªæ˜¯è®°å½•æ—¥å¿—
            if updated_mappings:
                logger.info(f"æ›´æ–°äº†{provider}çš„{len(updated_mappings)}ä¸ªæ¨¡å‹æ˜ å°„")
                for mapping in updated_mappings:
                    logger.info(f"  {mapping['frontend']} -> {mapping['backend']}")
            
            return {
                'success': True,
                'updated_mappings': updated_mappings,
                'message': f'æˆåŠŸæ›´æ–°{len(updated_mappings)}ä¸ªæ¨¡å‹æ˜ å°„'
            }
            
        except Exception as e:
            logger.error(f"æ›´æ–°æ¨¡å‹æ˜ å°„å¤±è´¥: {str(e)}")
            return {'success': False, 'error': f'æ›´æ–°æ¨¡å‹æ˜ å°„å¤±è´¥: {str(e)}'}

# å…¨å±€AIæœåŠ¡ç®¡ç†å™¨å®ä¾‹
ai_service = AIServiceManager()